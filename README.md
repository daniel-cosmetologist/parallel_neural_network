# Parallel neural network training
Utilizing multithreaded performace capabilities to decrease the training time of 
a neural network using OpenMP

# mnist-from-scratch
Code for training basic neural networks, especially the MNIST numbers dataset.

### Get the training dataset
```
kaggle datasets download -d oddrationale/mnist-in-csv
unzip mnist-in-csv.zip -d data
```

### Assemble and start the project
```
make
```

# If you want to measure time
```
time ./main
```

But don't forget to reassemble the project before that
```
make clean
make
```

### Video
[![Watch the video](https://img.youtube.com/vi/ReOxVMxS83o/maxresdefault.jpg)](https://youtu.be/ReOxVMxS83o)


### About (Russian)

OpenMP — это API для создания мультипоточных программ с разделяемой памятью, который позволяет программистам легко параллелизовать существующий код. Мультипоточная программа с разделяемой памятью позволяет запускать несколько параллельных потоков для увеличения пропускной способности.

В многопоточной программе с разделяемой памятью каждый поток выполняется на ядре процессора и может иметь доступ к общим глобальным переменным и ресурсам ОС. Потоки могут выполняться на одном ядре и имеют свой собственный стек и набор регистров для независимой работы.

С помощью OpenMP можно распараллелить код, добавив директиву 

#   pragma omp parallel for 

к циклам. Это распределит выполнение циклов по доступным ядрам процессора или потокам, позволяя выполнить код быстрее. Например, двумерный массив может быть разделен между ядрами так, что каждое ядро обрабатывает отдельные строки массива одновременно.

Можно регулировать количество потоков с помощью директивы NUM_THREADS, указывая, сколько потоков должно быть использовано для параллельной обработки. Это позволяет более гибко управлять нагрузкой на процессор и оптимизировать производительность программы.

Однако важно помнить, что не весь код подходит для параллелизации. Код, зависящий от предыдущих вычислений, должен выполняться последовательно. Например, обновление весов в нейронной сети в процессе обучения должно происходить последовательно.

При использовании большего числа потоков, чем необходимо, могут возникнуть накладные расходы, которые ухудшают общую производительность. Профилирование и тестирование программы на разном количестве потоков поможет найти оптимальное количество потоков для конкретной задачи.
